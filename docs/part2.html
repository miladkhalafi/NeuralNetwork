<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>مدل نرون و معماری شبکه</title>
    <style>
        body {
            font-family: 'B Nazanin', Tahoma, sans-serif;
            line-height: 1.8;
            margin: 20px;
            background-color: #f4f4f4;
            color: #333;
        }
        .container {
            max-width: 800px;
            margin: auto;
            background: #fff;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 0 10px rgba
            (0,0,0,0.1);
        }
        h2, h3, h4 {
            color: #0056b3;
            border-bottom: 2px solid #eee;
            padding-bottom: 5px;
            margin-top: 30px;
        }
        ul {
            list-style-type: square;
            padding-right: 20px;
        }
        li {
            margin-bottom: 8px;
        }
        p {
            margin-bottom: 10px;
        }
        .formula {
            background-color: #e9ecef;
            padding: 10px;
            border-radius: 5px;
            margin: 15px 0;
            overflow-x: auto;
            direction: ltr; /* For correct display of math */
        }
        .note {
            background-color: #d1ecf1;
            border-left: 5px solid #007bff;
            padding: 10px;
            margin: 15px 0;
            border-radius: 5px;
        }
        .exercise {
            background-color: #f8f9fa;
            border: 1px dashed #ced4da;
            padding: 15px;
            margin-top: 20px;
            border-radius: 5px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: right;
        }
        th {
            background-color: #f2f2f2;
        }
        .chart-container {
            width: 100%;
            max-width: 400px; /* Adjust as needed */
            margin: 20px auto;
            background-color: #e0f7fa;
            border: 1px dashed #00bcd4;
            padding: 10px;
            border-radius: 5px;
            text-align: center;
        }
        canvas {
            display: block; /* To remove extra space below canvas */
            width: 100%; /* Ensure canvas fills its container */
            height: 200px; /* Fixed height for consistent look */
        }
    </style>
    <script type="text/javascript" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

</head>
<body>
    <div class="container">
        <h2>مقدمه</h2>
        <p>این فصل به "مدل نرون و معماری شبکه" می‌پردازد. هدف اصلی آن، آشنایی با نحوه کارکرد یک نرون ساده، چگونگی اتصال نرون‌ها به هم برای ساخت شبکه‌های مختلف، و در نهایت، درک عملکرد این شبکه‌ها از طریق مثال‌های عملی است.</p>

        <h2>مدل نرون (نرون تک ورودی)</h2>
        <p>در این بخش، یک نرون (واحد اصلی شبکه عصبی) را بررسی می‌کنیم که فقط یک ورودی دارد. تصور کنید یک نرون دارید. این نرون اجزای زیر را دارد:</p>
        <ul>
            <li><strong>ورودی ($p$)</strong>: یک عدد تکی (اسکالر) که به نرون داده می‌شود.</li>
            <li><strong>وزن ($w$)</strong>: یک عدد تکی دیگر که اهمیت ورودی را مشخص می‌کند. این وزن، ورودی را "سنگین" می‌کند.</li>
            <li><strong>بایاس ($b$)</strong>: یک عدد اضافی که به خروجی جمع‌کننده اضافه می‌شود و نقش تنظیم‌کننده را دارد.</li>
            <li><strong>ورودی شبکه ($n$)</strong>: این بخش، حاصل‌ضرب وزن در ورودی را به علاوه بایاس، جمع می‌کند. فرمول آن به صورت زیر است:
                <div class="formula">
                    $$n = wp + b$$
                </div>
            </li>
            <li><strong>تابع انتقال ($f$)</strong>: این یک نوع تابع ریاضی است که ورودی شبکه ($n$) را دریافت می‌کند و آن را به یک خروجی خاص تبدیل می‌کند.</li>
            <li><strong>خروجی نرون ($a$)</strong>: این خروجی نهایی نرون است که از اعمال تابع انتقال به ورودی شبکه ($n$) به دست می‌آید:
                <div class="formula">
                    $$a = f(wp + b)$$
                </div>
            </li>
        </ul>

        <h2>توابع انتقال</h2>
        <p>توابع انتقال، مغز پردازشی نرون هستند که خروجی را تعیین می‌کنند. این توابع می‌توانند خطی یا غیرخطی باشند. سه نوع مهم از آن‌ها را بررسی می‌کنیم:</p>
        <ol>
            <li><strong>تابع محدود کننده سخت (Hard Limit)</strong>:
                <p>این تابع مثل یک کلید عمل می‌کند. فرمول آن به صورت زیر است:</p>
                <div class="formula">
                    $$a = \begin{cases} 0 & \text{if } n < 0 \\ 1 & \text{if } n \ge 0 \end{cases}$$
                </div>
                <div class="chart-container">
                    <p>برای نمایش این نمودار، لطفاً کتابخانه Chart.js را به صفحه خود اضافه کرده و تابع <code>createChart('hard-limit-chart', 'Hard Limit', n => (n >= 0 ? 1 : 0), true, -0.5, 1.5);</code> را در بخش JavaScript فعال کنید.</p>
                    <canvas id="hard-limit-chart"></canvas>
                </div>
                <p>این تابع برای دسته‌بندی چیزها به دو گروه (مثلاً بله یا خیر) استفاده می‌شود.</p>
            </li>
            <li><strong>تابع خطی (Linear)</strong>:
                <p>این تابع خیلی ساده است. خروجی آن دقیقاً برابر با ورودی آن ($n$) است. فرمول آن به صورت زیر است:</p>
                <div class="formula">
                    $$a = n$$
                </div>
                <div class="chart-container">
                    <p>برای نمایش این نمودار، لطفاً کتابخانه Chart.js را به صفحه خود اضافه کرده و تابع <code>createChart('linear-chart', 'Linear', n => n, false, -5, 5);</code> را در بخش JavaScript فعال کنید.</p>
                    <canvas id="linear-chart"></canvas>
                </div>
                <p>یعنی اگر ورودی 1.6 باشد، خروجی هم 1.6 است.</p>
            </li>
            <li><strong>تابع Log-Sigmoid</strong>:
                <p>این تابع کمی پیچیده‌تر است و خروجی آن همیشه بین صفر و یک قرار می‌گیرد. فرمول آن به صورت زیر است:</p>
                <div class="formula">
                    $$a = \frac{1}{1+e^{-n}}$$
                </div>
                <div class="chart-container">
                    <p>برای نمایش این نمودار، لطفاً کتابخانه Chart.js را به صفحه خود اضافه کرده و تابع <code>createChart('log-sigmoid-chart', 'Log-Sigmoid', n => 1 / (1 + Math.exp(-n)), false, -0.1, 1.1);</code> را در بخش JavaScript فعال کنید.</p>
                    <canvas id="log-sigmoid-chart"></canvas>
                </div>
                <p>این تابع به دلیل اینکه قابلیت "مشتق‌پذیری" دارد (یعنی می‌توانیم نرخ تغییر آن را حساب کنیم)، در شبکه‌هایی که یادگیری انجام می‌دهند، خیلی کاربرد دارد.</p>
            </li>
        </ol>
        <div class="note">
            <p><strong>کاربرد در نرم‌افزار متلب:</strong> نرم‌افزار متلب دستورات خاصی برای استفاده از این توابع انتقال دارد.</p>
        </div>

        <h3>جدول توابع انتقال (بر اساس جدول 2.1)</h3>
        <table>
            <thead>
                <tr>
                    <th>نام تابع</th>
                    <th>رابطه ورودی/خروجی</th>
                    <th>نماد</th>
                    <th>تابع متلب</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Hard Limit</td>
                    <td>$a = \begin{cases} 0 & \text{if } n < 0 \\ 1 & \text{if } n \ge 0 \end{cases}$</td>
                    <td>hardlim</td>
                    <td><code>hardlim(n)</code></td>
                </tr>
                <tr>
                    <td>Symmetrical Hard Limit</td>
                    <td>$a = \begin{cases} -1 & \text{if } n < 0 \\ 1 & \text{if } n \ge 0 \end{cases}$</td>
                    <td>hardlims</td>
                    <td><code>hardlims(n)</code></td>
                </tr>
                <tr>
                    <td>Linear</td>
                    <td>$a = n$</td>
                    <td>purelin</td>
                    <td><code>purelin(n)</code></td>
                </tr>
                <tr>
                    <td>Saturating Linear</td>
                    <td>$a = \begin{cases} 0 & \text{if } n < 0 \\ n & \text{if } 0 \le n \le 1 \\ 1 & \text{if } n > 1 \end{cases}$</td>
                    <td>satlin</td>
                    <td><code>satlin(n)</code></td>
                </tr>
                <tr>
                    <td>Symmetric Saturating Linear</td>
                    <td>$a = \begin{cases} -1 & \text{if } n < -1 \\ n & \text{if } -1 \le n \le 1 \\ 1 & \text{if } n > 1 \end{cases}$</td>
                    <td>satlins</td>
                    <td><code>satlins(n)</code></td>
                </tr>
                <tr>
                    <td>Log-Sigmoid</td>
                    <td>$a = \frac{1}{1+e^{-n}}$</td>
                    <td>logsig</td>
                    <td><code>logsig(n)</code></td>
                </tr>
                <tr>
                    <td>Hyperbolic Tangent Sigmoid</td>
                    <td>$a = \frac{e^n - e^{-n}}{e^n + e^{-n}}$</td>
                    <td>tansig</td>
                    <td><code>tansig(n)</code></td>
                </tr>
                <tr>
                    <td>Positive Linear</td>
                    <td>$a = \begin{cases} 0 & \text{if } n < 0 \\ n & \text{if } n \ge 0 \end{cases}$</td>
                    <td>poslin</td>
                    <td><code>poslin(n)</code></td>
                </tr>
                <tr>
                    <td>Competitive</td>
                    <td>$a_k = 1$ if $n_k$ is max, else $a_k = 0$</td>
                    <td>compet</td>
                    <td><code>compet(n)</code></td>
                </tr>
            </tbody>
        </table>

        <h2>نرون چند ورودی</h2>
        <p>بر خلاف نرون تک ورودی، یک نرون می‌تواند چندین ورودی داشته باشد.</p>
        <ul>
            <li><strong>ورودی‌ها</strong>: فرض کنید چندین ورودی دارید: $P_1, P_2, \ldots, P_R$.</li>
            <li><strong>وزن‌ها</strong>: برای هر ورودی، یک وزن جداگانه وجود دارد ($W_{1,1}$ برای $P_1$، $W_{1,2}$ برای $P_2$ و ...).</li>
            <li><strong>بایاس ($b$)</strong>: این هم مثل قبل، یک مقدار تنظیم‌کننده است.</li>
            <li><strong>ورودی شبکه ($n$)</strong>: در اینجا، هر ورودی در وزن خودش ضرب می‌شود، سپس نتایج همه این ضرب‌ها با هم جمع می‌شوند، و در نهایت بایاس هم به آن‌ها اضافه می‌شود. فرمول آن به صورت زیر است:
                <div class="formula">
                    $$n = W_{1,1}P_1 + W_{1,2}P_2 + \ldots + W_{1,R}P_R + b$$
                </div>
                <p>این رابطه را می‌توان به صورت برداری نیز نوشت:</p>
                <div class="formula">
                    $$n = \mathbf{w}^T \mathbf{p} + b$$
                </div>
                <p>که در آن $\mathbf{w}$ بردار وزن‌ها و $\mathbf{p}$ بردار ورودی‌ها است.</p>
            </li>
            <li><strong>تابع انتقال ($f$) و خروجی نرون ($a$)</strong>: مثل نرون تک ورودی، این بخش ($n$) وارد تابع انتقال می‌شود تا خروجی نهایی ($a$) را بدهد.
                <div class="formula">
                    $$a = f(n)$$
                </div>
            </li>
        </ul>
        <div class="note">
            <h3>نکات مهم درباره وزن‌ها و ورودی‌ها:</h3>
            <ul>
                <li><strong>اندیس‌گذاری وزن‌ها</strong>: وزن‌ها معمولاً با دو عدد مشخص می‌شوند. مثلاً $W_{1,2}$. عدد اول (1) نشان می‌دهد که این وزن مربوط به نرون شماره 1 است (که در مثال‌های ما معمولاً یک نرون داریم). عدد دوم (2) نشان می‌دهد که این وزن مربوط به ورودی شماره 2 است.</li>
                <li><strong>تعداد ورودی‌ها</strong>: تعداد ورودی‌های یک نرون به خود مسئله بستگی دارد. مثلاً اگر می‌خواهید شرایط آب و هوایی را پیش‌بینی کنید و دما، رطوبت و سرعت باد، ورودی‌های شما باشند، پس نرون شما 3 ورودی خواهد داشت.</li>
            </ul>
        </div>

        <h2>معماری شبکه (ساختارهای شبکه)</h2>
        <p>معمولاً یک نرون تکی برای حل مسائل پیچیده کافی نیست، بنابراین از چندین نرون استفاده می‌کنیم که به هم متصل شده‌اند و یک "شبکه" را تشکیل می‌دهند.</p>

        <h3>شبکه تک لایه از نرون‌ها</h3>
        <p>این ساده‌ترین نوع شبکه است. در اینجا، تعدادی نرون به صورت موازی کنار هم قرار می‌گیرند و همگی به یک سری ورودی مشترک وصل می‌شوند. این مجموعه از نرون‌ها یک "لایه" را تشکیل می‌دهند.</p>
        <ul>
            <li><strong>تعداد ورودی‌ها ($R$)</strong>: تعداد چیزهایی که به شبکه وارد می‌شوند.</li>
            <li><strong>تعداد نرون‌ها ($S$)</strong>: تعداد نرون‌هایی که در این لایه وجود دارند.</li>
            <li><strong>ماتریس وزن ($\mathbf{W}$)</strong>: این ماتریس، همه وزن‌ها را برای همه نرون‌ها و همه ورودی‌ها در خود جای می‌دهد. ابعاد آن $S \times R$ است.
                <div class="formula">
                    $$\mathbf{W} = \begin{pmatrix} w_{1,1} & w_{1,2} & \ldots & w_{1,R} \\ w_{2,1} & w_{2,2} & \ldots & w_{2,R} \\ \vdots & \vdots & \ddots & \vdots \\ w_{S,1} & w_{S,2} & \ldots & w_{S,R} \end{pmatrix}$$
                </div>
            </li>
            <li><strong>بردار بایاس ($\mathbf{b}$)</strong>: برای هر نرون یک بایاس جداگانه وجود دارد. ابعاد آن $S \times 1$ است.</li>
            <li><strong>ورودی شبکه برداری ($\mathbf{n}$)</strong>:
                <div class="formula">
                    $$\mathbf{n} = \mathbf{W}\mathbf{p} + \mathbf{b}$$
                </div>
            </li>
            <li><strong>خروجی شبکه ($\mathbf{a}$)</strong>: این خروجی نهایی لایه است که شامل خروجی هر نرون می‌شود.
                <div class="formula">
                    $$\mathbf{a} = f(\mathbf{n})$$
                </div>
                <p>که در آن تابع $f$ به صورت عنصر به عنصر روی بردار $\mathbf{n}$ اعمال می‌شود.</p>
            </li>
        </ul>

        <h3>شبکه چند لایه از نرون‌ها</h3>
        <p>این شبکه‌ها پیچیده‌تر و قدرتمندتر هستند و از چندین لایه نرون تشکیل شده‌اند. خروجی یک لایه، ورودی لایه بعدی می‌شود.</p>
        <ul>
            <li><strong>نمادگذاری لایه‌ها</strong>: برای تشخیص هر لایه، شماره لایه به صورت بالانویس روی متغیرها آورده می‌شود. مثلاً $\mathbf{W}^1$ ماتریس وزن لایه اول است.</li>
            <li><strong>لایه‌های پنهان</strong>: به جز لایه آخری که خروجی نهایی شبکه را می‌دهد، بقیه لایه‌ها را "لایه‌های پنهان" می‌نامند.</li>
            <li><strong>قدرت بیشتر</strong>: شبکه‌های چند لایه خیلی قوی‌تر از شبکه‌های تک لایه هستند و می‌توانند مسائل پیچیده‌تری را حل کنند.</li>
            <li><strong>انتخاب ورودی و خروجی</strong>: تعداد ورودی‌ها و خروجی‌های شبکه مستقیماً به خود مسئله بستگی دارد.</li>
            <li><strong>انتخاب تابع انتقال لایه خروجی</strong>: تابعی که برای لایه آخر انتخاب می‌کنید، باید با نوع خروجی که می‌خواهید، سازگار باشد (مثلاً اگر می‌خواهید خروجی بین 0 و 1 باشد، از تابع "logsig" استفاده می‌کنید).</li>
            <li><strong>تعداد نرون‌ها در لایه‌های پنهان</strong>: انتخاب تعداد نرون‌ها در لایه‌های پنهان یک هنر است و هیچ قانون سفت و سختی برای آن وجود ندارد؛ به تجربه و آزمون و خطا نیاز دارد.</li>
        </ul>

        <h2>بایاس و اهمیت آن</h2>
        <p>بایاس یک متغیر اضافی به شبکه اضافه می‌کند که قدرت آن را نسبت به یک شبکه بدون بایاس افزایش می‌دهد. بدون بایاس، اگر همه ورودی‌ها صفر باشند، خروجی هم صفر خواهد بود. اما با بایاس، می‌توانید حتی با ورودی‌های صفر، یک خروجی دلخواه داشته باشید.</p>

        <h2>شبکه‌های بازگشتی (Recurrent Network)</h2>
        <p>این نوع شبکه‌ها کمی متفاوت هستند. در آن‌ها، خروجی نرون‌ها (یا بخشی از آن) به عنوان ورودی به خود شبکه (یا همان نرون‌ها) برمی‌گردد. این کار باعث می‌شود شبکه "حافظه" داشته باشد و بتواند اطلاعات گذشته را در پردازش‌های فعلی خود دخیل کند.</p>
        <ul>
            <li><strong>بلوک تاخیر (Delay Block)</strong>: این بلوک سیگنال را به اندازه یک پله زمانی به تأخیر می‌اندازد. یعنی اگر ورودی در زمان حال $u(t)$ باشد، خروجی همان ورودی است ولی از زمان گذشته:
                <div class="formula">
                    $$a(t) = u(t-1)$$
                </div>
            </li>
            <li><strong>بلوک انتگرال‌گیر (Integrator)</strong>: این بلوک ورودی‌ها را در طول زمان جمع می‌کند و یک نوع حافظه جمع‌شونده ایجاد می‌کند. فرمول آن به صورت زیر است:
                <div class="formula">
                    $$a(t) = \int_{0}^{t} u(\tau) d\tau + a(0)$$
                </div>
            </li>
        </ul>
        <div class="note">
            <p><strong>قابلیت‌های شبکه‌های بازگشتی</strong>: این شبکه‌ها می‌توانند رفتارهای پیچیده و وابسته به زمان را مدل کنند، مثلاً در پردازش زبان طبیعی یا پیش‌بینی سری‌های زمانی کاربرد دارند.</p>
        </div>

        <h2>انتخاب ساختار شبکه</h2>
        <p>برای طراحی یک شبکه، باید به نکات زیر توجه کنیم:</p>
        <ol>
            <li><strong>تعداد ورودی‌ها</strong>: برابر با تعداد ورودی‌های مسئله است.</li>
            <li><strong>تعداد نرون‌های لایه خروجی</strong>: برابر با تعداد خروجی‌های مسئله است.</li>
            <li><strong>نوع تابع انتقال لایه خروجی</strong>: تا حدودی توسط مشخصات خروجی مسئله قابل تعیین است.</li>
        </ol>

        <h2>مسائل حل شده</h2>

        <h3>مسئله نمونه 1</h3>
        <p>فرض کنید یک نرون دارید با ورودی $p=2.0$، وزن $w=1.3$ و بایاس $b=3.0$.</p>
        <ul>
            <li><strong>الف) ورودی نهایی ($n$) به تابع انتقال چیست؟</strong>
                <div class="formula">
                    $$n = wp + b = (1.3)(2.0) + 3.0 = 2.6 + 3.0 = 5.6$$
                </div>
            </li>
            <li><strong>ب) خروجی نرون ($a$) چقدر است؟</strong>
                <p>خروجی را نمی‌توان تعیین کرد، زیرا تابع انتقال نرون مشخص نیست.</p>
            </li>
        </ul>

        <h3>مسئله نمونه 2</h3>
        <p>خروجی نرون مسئله قبل (با $n=5.6$) را در صورتی که دارای توابع انتقال زیر باشد، پیدا کنید:</p>
        <ul>
            <li><strong>الف) Hard Limit</strong>:
                <div class="formula">
                    $$a = \text{hardlim}(5.6) = 1.0 \quad (\text{چون } 5.6 \ge 0)$$
                </div>
            </li>
            <li><strong>ب) Linear</strong>:
                <div class="formula">
                    $$a = 5.6$$
                </div>
            </li>
            <li><strong>ج) Log-Sigmoid</strong>:
                <div class="formula">
                    $$a = \frac{1}{1+e^{-5.6}} = 0.9963$$
                </div>
            </li>
        </ul>

        <h3>مسئله نمونه 3</h3>
        <p>یک نرون دو ورودی با ماتریس وزن $\mathbf{W}=[\begin{matrix}3&2\end{matrix}]$ و بردار ورودی $\mathbf{p}=[\begin{matrix}-5\\6\end{matrix}]^{T}$ و بایاس $b=1.2$ داده شده است.</p>
        <ul>
            <li><strong>ابتدا ورودی شبکه ($n$) را محاسبه می‌کنیم:</strong>
                <div class="formula">
                    $$n = \mathbf{W}\mathbf{p} + b = (3 \times -5) + (2 \times 6) + 1.2 = -15 + 12 + 1.2 = -3 + 1.2 = -1.8$$
                </div>
            </li>
            <li><strong>حال خروجی را برای هر تابع انتقال می‌یابیم:</strong>
                <ul>
                    <li><strong>الف) برای تابع hard limit متقارن (hardlims):</strong>
                        <div class="formula">
                            $$a = \text{hardlims}(-1.8) = -1 \quad (\text{چون } n < 0)$$
                        </div>
                    </li>
                    <li><strong>ب) برای تابع خطی اشباعی (Saturating Linear - satlin):</strong>
                        <div class="formula">
                            $$a = \text{satlin}(-1.8) = 0 \quad (\text{چون } n < 0)$$
                        </div>
                    </li>
                    <li><strong>ج) برای تابع تانژانت هایپربولیک سیگموید (Hyperbolic-tangent-Sigmoid - tansig):</strong>
                        <div class="formula">
                            $$a = \text{tansig}(-1.8) = -0.9468$$
                        </div>
                    </li>
                </ul>
            </li>
        </ul>

        <h3>مسئله نمونه 4</h3>
        <p>یک شبکه عصبی تک لایه با 6 ورودی و 2 خروجی است. خروجی‌ها باید مقادیر پیوسته در فاصله 0 تا 1 داشته باشند.</p>
        <ul>
            <li><strong>الف) چه تعداد نرون مورد نیاز است؟</strong> 2 نرون (به ازای هر خروجی یک نرون).</li>
            <li><strong>ب) بعد ماتریس وزن چیست؟</strong>
                <p>ماتریس وزن ($\mathbf{W}$) دارای 2 سطر (متناظر با 2 نرون خروجی) و 6 ستون (متناظر با 6 ورودی) خواهد بود. یعنی ابعاد آن $2 \times 6$ است.</p>
            </li>
            <li><strong>ج) چه نوع تابع انتقالی می‌تواند استفاده شود؟</strong>
                <p>از بین توابع انتقالی که بررسی شد، تابع <code>logsig</code> (Log-Sigmoid) بهترین انتخاب است، زیرا خروجی بین 0 و 1 تولید می‌کند.</p>
            </li>
            <li><strong>د) آیا به بایاس نیازی هست؟</strong>
                <p>اطلاعات کافی برای تعیین نیاز یا عدم نیاز به بایاس در مسئله داده نشده است، اما عموماً استفاده از بایاس توصیه می‌شود.</p>
            </li>
        </ul>

        <h2>تمرینات</h2>
        <p>این بخش شامل تمریناتی است که به شما کمک می‌کند تا مفاهیم مدل نرون و معماری شبکه را بهتر درک کنید و آن‌ها را در موقعیت‌های مختلف به کار ببرید. این تمرینات شامل طراحی شبکه، انتخاب توابع انتقال و محاسبه خروجی‌ها در شرایط مختلف می‌شوند.</p>

        <h3>تمرین E.2.1</h3>
        <p>ورودی یک نرون تک ورودی 2.0، وزن آن 1.3 و بایاس آن 3.0 است. چه نوع توابع انتقالی از جدول 2.1 می‌توانند خروجی‌های زیر را تولید کنند؟</p>
        <ol type="i">
            <li>1.6</li>
            <li>1.0</li>
            <li>0.9963</li>
            <li>-1.0</li>
        </ol>

        <h3>تمرین E.2.2</h3>
        <p>یک نرون تک ورودی با بایاس را در نظر بگیرید. می‌خواهیم خروجی برای ورودی‌های کمتر از 3، -1 و برای ورودی‌های بزرگتر یا مساوی 3، +1 باشد.</p>
        <ol type="i">
            <li>چه نوع تابع انتقالی مورد نیاز است؟</li>
            <li>چه بایاسی پیشنهاد می‌کنید؟ آیا بایاس شما به وزن ورودی ارتباطی دارد؟ اگر بله، چگونه؟</li>
            <li>شبکه خود را با نام تابع انتقال، بایاس و وزن خلاصه کنید.</li>
            <li>یک دیاگرام از شبکه بکشید. عملکرد شبکه را با استفاده از متلب بررسی کنید.</li>
        </ol>

        <h3>تمرین E.2.3</h3>
        <p>یک نرون دو ورودی با ماتریس وزن $W=[\begin{matrix}3&2\end{matrix}]$ و بردار ورودی $p=[-5&7\end{matrix}]^{T}$ داده شده است. می‌خواهیم خروجی 0.5 داشته باشیم. آیا ترکیبی از بایاس و تابع انتقال می‌تواند این امر را ممکن کند؟</p>
        <ol type="i">
            <li>آیا تابع انتقالی از جدول 2.1 وجود دارد که اگر بایاس صفر باشد، این کار را انجام دهد؟</li>
            <li>آیا بایاسی وجود دارد که اگر از تابع انتقال خطی استفاده شود، این کار را انجام دهد؟ اگر بله، چیست؟</li>
            <li>آیا بایاسی وجود دارد که اگر از تابع انتقال log-sigmoid استفاده شود، این کار را انجام دهد؟ اگر بله، چیست؟</li>
            <li>آیا بایاسی وجود دارد که اگر از تابع انتقال "hard limit متقارن" استفاده شود، این کار را انجام دهد؟ اگر بله، چیست؟</li>
        </ol>

        <h3>تمرین E.2.4</h3>
        <p>یک شبکه عصبی دو لایه قرار است چهار ورودی و شش خروجی داشته باشد. محدوده خروجی‌ها باید پیوسته بین 0 و 1 باشد. چه چیزی می‌توانید در مورد معماری شبکه بگویید؟ به طور خاص:</p>
        <ol type="i">
            <li>چند نرون در هر لایه مورد نیاز است؟</li>
            <li>ابعاد ماتریس‌های وزن لایه اول و دوم چیست؟</li>
            <li>چه نوع توابع انتقالی می‌توانند در هر لایه استفاده شوند؟</li>
            <li>آیا بایاس در هر لایه مورد نیاز است؟</li>
        </ol>
    </div>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            }
        };

        window.onload = function() {
            // Function to draw a plot using Chart.js
            function createChart(canvasId, label, dataFunction, step = false, yMin = -0.1, yMax = 1.1) {
                const ctx = document.getElementById(canvasId);
                if (ctx) {
                    const dataPoints = [];
                    for (let n = -5; n <= 5; n += 0.1) { // Range for n
                        dataPoints.push({ x: n, y: dataFunction(n) });
                    }

                    new Chart(ctx, {
                        type: 'line',
                        data: {
                            datasets: [{
                                label: label,
                                data: dataPoints,
                                borderColor: 'rgb(75, 192, 192)',
                                borderWidth: 2,
                                pointRadius: 0, // No points for a continuous line
                                stepped: step ? 'before' : false // For step-like functions
                            }]
                        },
                        options: {
                            responsive: true,
                            maintainAspectRatio: false, // Allow custom height
                            scales: {
                                x: {
                                    type: 'linear',
                                    position: 'bottom',
                                    title: {
                                        display: true,
                                        text: 'n (ورودی شبکه)'
                                    }
                                },
                                y: {
                                    min: yMin,
                                    max: yMax,
                                    title: {
                                        display: true,
                                        text: 'a (خروجی)'
                                    }
                                }
                            },
                            plugins: {
                                legend: {
                                    display: true
                                }
                            }
                        }
                    });
                }
            }

            // Call createChart for each function type
            // You need to UNCOMMENT the Chart.js script tag in <head> for these to work.
            createChart('hard-limit-chart', 'Hard Limit', n => (n >= 0 ? 1 : 0), true, -0.5, 1.5);
            createChart('linear-chart', 'Linear', n => n, false, -5, 5); // Adjust Y-min/max for linear
            createChart('log-sigmoid-chart', 'Log-Sigmoid', n => 1 / (1 + Math.exp(-n)), false, -0.1, 1.1);

            // If Chart.js is NOT included, the following messages will show in the placeholders.
            const placeholders = document.querySelectorAll('.chart-container p');
            placeholders.forEach(p => {
                const canvas = p.parentNode.querySelector('canvas');
                if (!canvas || typeof Chart === 'undefined') { // If canvas not found or Chart.js not loaded
                    p.style.display = 'block'; // Show the message
                } else {
                    p.style.display = 'none'; // Hide the message if chart is drawn
                }
            });
        };
    </script>
</body>
</html>