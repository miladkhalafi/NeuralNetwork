<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>خلاصه و مقایسه شبکه‌های عصبی</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    <link href="https://fonts.googleapis.com/css2?family=Vazirmatn:wght@300;400;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Vazirmatn', 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.8;
            margin: 0;
            padding: 0;
            background-color: #f4f7f6;
            color: #333;
            text-align: right;
        }
        .container {
            max-width: 1000px;
            margin: 30px auto;
            background-color: #ffffff;
            padding: 30px 40px;
            border-radius: 12px;
            box-shadow: 0 6px 12px rgba(0, 0, 0, 0.08);
        }
        h1, h2, h3 {
            color: #2c3e50;
            border-bottom: 2px solid #e0e0e0;
            padding-bottom: 10px;
            margin-top: 30px;
        }
        h1 {
            font-size: 2.5em;
            text-align: center;
            border-bottom: 3px solid #3498db;
            padding-bottom: 15px;
            margin-bottom: 40px;
            color: #34495e;
        }
        h2 {
            font-size: 1.8em;
            color: #3498db;
            border-bottom-color: #3498db;
        }
        h3 {
            font-size: 1.4em;
            color: #2ecc71;
            border-bottom-color: #2ecc71;
        }
        p {
            margin-bottom: 15px;
            text-align: justify;
        }
        ul {
            list-style-type: none;
            padding: 0;
            margin-bottom: 20px;
        }
        ul li {
            background: #ecf0f1;
            margin: 8px 0;
            padding: 10px 15px;
            border-radius: 8px;
            border-right: 5px solid #3498db;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 30px 0;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.05);
            border-radius: 10px;
            overflow: hidden;
        }
        th, td {
            border: 1px solid #dee7ed;
            padding: 12px 15px;
            text-align: right;
        }
        th {
            background-color: #3498db;
            color: white;
            font-weight: bold;
            text-transform: uppercase;
        }
        tr:nth-child(even) {
            background-color: #f8fbfd;
        }
        tr:hover {
            background-color: #e9f5fd;
        }
        .math-formula {
            direction: ltr;
            text-align: center;
            margin: 25px 0;
            background-color: #f0f4f7;
            padding: 15px;
            border-radius: 8px;
            border: 1px solid #dcdfe4;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>خلاصه و مقایسه شبکه‌های عصبی</h1>

        <h2>خلاصه صفحات ۲ تا ۴</h2>
        <p>
            در این فصل، هدف اصلی توضیح ماهیت شبکه‌های عصبی با کمک یک مسئله شناسایی الگو است. ابتدا ایده شناسایی و طبقه‌بندی الگوها مطرح می‌شود و سپس سه نوع شبکه عصبی شامل پرسپترون، همینگ و هاپفیلد برای حل مسئله شناسایی الگو فرمول‌بندی می‌شوند.
        </p>

        <h2>شناسایی الگو</h2>
        <p>
            مسئله و مفاهیم شناسایی الگو به عنوان یک عامل مهم در طراحی سیستم‌های اطلاعاتی مورد توجه قرار گرفته است. ساختار کلی فرآیند شناسایی الگو و تصمیم‌گیری شامل چهار موضوع اصلی است:
        </p>
        <ul>
            <li>چیزی یا موضوعی اتفاق افتاده است.</li>
            <li>این اتفاق توسط یک سیگنال نمایش داده می‌شود.</li>
            <li>سیگنال مشاهده شده با سیگنال اصلی ارسالی یکسان نیست.</li>
            <li>بر اساس سیگنال مشاهده شده، تصمیم‌گیرنده باید در مورد مسئله یا موضوع واقعی تصمیم بگیرد.</li>
        </ul>
        <p>
            در طراحی یک سیستم شناسایی الگو، ابتدا اشیاء مورد شناسایی باید به الگوها و بردارهای ورودی تبدیل شوند که به سیستم شناسایی اعمال می‌شوند. این فرآیند کدگذاری است و از نظر هندسی، هر شی یا موضوع شناسایی را می‌توان به عنوان یک نقطه در فضای چندبعدی اقلیدسی در نظر گرفت. سپس، ویژگی‌های مهم از روی داده‌های ورودی اندازه‌گیری شده استخراج و ابعاد بردار الگوها کاهش می‌یابد. اطلاعاتی که شبکه عصبی بر اساس آن‌ها تصمیم‌گیری می‌کند، از داده‌های یادگیری استخراج می‌شوند و در پارامترهای آزاد شبکه (مانند ماتریس وزن و بردار بایاس) توسط مکانیزم یادگیری ذخیره می‌گردند.
        </p>

        <h2>بیان صورت مسئله (مثال سیب و پرتقال)</h2>
        <p>
            فرض کنید دو نوع میوه، سیب و پرتقال، قرار است به صورت خودکار در یک انبار جدا شوند. میوه‌ها از طریق ریلی به یک حسگر هدایت می‌شوند و دستگاه سه ویژگی آن‌ها را اندازه‌گیری می‌کند: شکل، زبری/صافی سطح، و وزن. یک دستگاه اندازه‌گیری ساده، برای شکل تقریباً گرد مقدار \(1\) و برای شکل تقریباً بیضوی مقدار \(-1\) را نشان می‌دهد. حسگر بافت برای سطح صاف مقدار \(1\) و برای میوه ناصاف مقدار \(-1\) را نمایش می‌دهد. دستگاه اندازه‌گیری وزن برای وزن کمتر از \(200\) گرم مقدار \(-1\) و برای وزن بیشتر از \(200\) گرم مقدار \(1\) را نشان می‌دهد.
        </p>
        <p>
            اگر فرم کلی الگو به صورت \( P = \begin{bmatrix} \text{Shape} \\ \text{texture} \\ \text{weight} \end{bmatrix} \) باشد، آنگاه پرتقال و سیب به ترتیب الگوهای \( P_{1} = \begin{bmatrix} 1 \\ -1 \\ -1 \end{bmatrix} \) و \( P_{2} = \begin{bmatrix} 1 \\ 1 \\ -1 \end{bmatrix} \) را خواهند داشت. شبکه عصبی یک بردار ورودی را برای هر میوه دریافت می‌کند و تصمیم می‌گیرد که آیا این میوه پرتقال است یا سیب.
        </p>

        <h2>خلاصه صفحات ۵ تا ۸ (پرسپترون)</h2>
        <p>
            پرسپترون اولین شبکه‌ای است که مورد بحث قرار می‌گیرد. یک پرسپترون تک لایه با تابع انتقال Hard Limit متقارن، بردارهای ورودی را به دو دسته تقسیم می‌کند. خط جداکننده در جایی است که ورودی شبکه (\(n\)) برابر با صفر می‌شود. مرز تصمیم‌گیری همیشه بر بردار وزن عمود است و مکان آن را می‌توان با تغییر مقدار \(b\) جابجا کرد. بنابراین، یک نرون پرسپترون می‌تواند فضای ورودی را به دو ناحیه مجزا تقسیم کند. معادله مرز جداکننده \( W\underline{P} + b = 0 \) است. از آنجایی که مرز باید خطی باشد، یک پرسپترون تک لایه فقط برای جداسازی الگوهایی که به صورت خطی قابل تفکیک هستند مناسب است. برای حل مسئله اصلی سیب و پرتقال، از آنجایی که بردارهای ورودی سه‌بعدی هستند، پرسپترون باید سه ورودی داشته باشد.
        </p>
        <img src="images/perceptron.png" alt="پرسپترون تک لایه" style="width: 220px; max-width: 100%; margin: 20px auto; display: block; border-radius: 8px; box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);">
        <p style="text-align: center;">
            یک پرسپترون تک لایه با تابع انتقال Hard Limit متقارن را نشان می‌دهد.
        </p>
        <p>
            برای تشخیص میوه‌های پرتقال و سیب، باید مقدار بایاس و عناصر ماتریس وزن به گونه‌ای انتخاب شوند که پرسپترون بتواند آن‌ها را از هم تشخیص دهد. فرض بر این است اگر ورودی سیب باشد، خروجی \(1\) و اگر پرتقال باشد، خروجی \(-1\) خواهد بود. بردار وزن در این حالت \( W = [0 \ 1 \ 0] \) و بایاس \( b = 0 \) است. بردار وزن بر مرز تصمیم‌گیری عمود است و به سمت ناحیه‌ای که شامل الگوی سیب (\( P_{2} \)) است، اشاره می‌کند. این ناحیه باید برای پرسپترون خروجی \(1\) داشته باشد. چون ناحیه تصمیم‌گیری از مرکز عبور می‌کند، بایاس صفر است.
        </p>
        <p>
            اگر یک پرتقال بیضوی شکل (غیر ایده‌آل) از حسگر عبور کند، بردار ورودی آن \( P = \begin{bmatrix} -1 \\ -1 \\ -1 \end{bmatrix} \) خواهد بود. شبکه طراحی شده، هر بردار ورودی را که به الگوی پرتقال نزدیک‌تر باشد (از نظر فاصله اقلیدسی) در گروه پرتقال دسته‌بندی می‌کند.
        </p>

        <h2>خلاصه صفحات ۹ تا ۱۲ (شبکه همینگ)</h2>
        <p>
            شبکه همینگ دارای لایه‌های پیشخوردی و برگشتی است. در این شبکه، هدف تصمیم‌گیری درباره نزدیک‌ترین بردار Prototype به بردار ورودی است. به ازای هر الگوی Prototype، یک نرون در لایه بازگشتی وجود دارد. وقتی لایه بازگشتی همگرا می‌شود، تنها یک نرون در این لایه خروجی غیر صفر خواهد داشت و آن نرون نشان‌دهنده الگویی است که به بردار ورودی نزدیک‌تر است.
        </p>

        <h3>لایه پیشخوردی</h3>
        <p>
            این لایه به محاسبه همبستگی (ضرب داخلی) بین هر الگوی Prototype و الگوی ورودی می‌پردازد. سطرهای ماتریس وزن بر اساس الگوهای Prototype شکل گرفته‌اند. با اضافه کردن \(R\) به ضرب‌های داخلی، تضمین می‌شود که خروجی لایه پیشخوردی هرگز منفی نشود. نرون لایه پیشخوردی که دارای بزرگ‌ترین خروجی است، نشان‌دهنده الگوی Prototype‌ای است که نزدیک‌ترین فاصله همینگ را با الگوی ورودی دارد.
        </p>

        <h3>لایه بازگشتی</h3>
        <p>
            لایه بازگشتی به عنوان لایه رقابتی نیز شناخته می‌شود. نرون‌های این لایه با کمک خروجی‌های لایه پیشخوردی مقداردهی اولیه می‌شوند و با یکدیگر رقابت می‌کنند تا نرون برنده مشخص شود. پس از پایان رقابت، تنها یک نرون خروجی غیر صفر خواهد داشت که نشان‌دهنده گروه مربوط به ورودی است. تابع تبدیلی PosLin برای مقادیر مثبت خطی و برای مقادیر منفی صفر است. نتایج عملکرد لایه بازگشتی نشان می‌دهد که خروجی تمام نرون‌ها به جز نرونی که دارای بزرگ‌ترین مقدار اولیه است، برابر با صفر می‌شود.
        </p>
        <p>
            برای یک پرتقال بیضوی شکل، شبکه همینگ با همگرایی صحیح، الگوی Prototype اول (پرتقال) را برای بردار ورودی انتخاب می‌کند، زیرا فاصله همینگ Prototype پرتقال از بردار ورودی کمتر از فاصله همینگ Prototype سیب از بردار ورودی است.
        </p>

        <h2>خلاصه صفحات ۱۳ تا ۱۵ (شبکه هاپفیلد)</h2>
        <p>
            شبکه هاپفیلد یک شبکه بازگشتی است که می‌تواند به تنهایی وظیفه هر دو لایه در شبکه همینگ را انجام دهد. در این شبکه، نرون‌ها از طریق بردارهای ورودی مقداردهی اولیه می‌شوند و شبکه شروع به تکرار می‌کند تا زمانی که خروجی‌ها همگرا شوند. خروجی نهایی باید برابر با یکی از Prototypeها باشد. در اینجا، به جای اینکه نرون غیر صفر نشان‌دهنده Prototype انتخاب شده باشد، Prototype انتخابی در خروجی شبکه تولید می‌شود.
        </p>
        <p>
            معادلات بیان‌کننده عملکرد شبکه هاپفیلد شامل مقداردهی اولیه خروجی‌ها و به‌روزرسانی آن‌ها با استفاده از تابع تبدیلی satlins است. تابع satlins در فاصله \(-1\) و \(1\) خطی است و برای ورودی‌های بزرگ‌تر از \(1\) به \(1\) و برای ورودی‌های کوچک‌تر از \(-1\) به \(-1\) اشباع می‌شود. شکل‌گیری ماتریس وزن و بردار بایاس در شبکه هاپفیلد پیچیده‌تر از شبکه همینگ است.
        </p>
        <p>
            برای توضیح نحوه عملکرد شبکه هاپفیلد در مسئله سیب و پرتقال، با توجه به ماتریس وزن و بردار بایاس داده شده، مشاهده می‌شود که در هر دو الگوی سیب و پرتقال، عنصر اول برابر با \(1\) و عنصر سوم برابر با \(-1\) است. بنابراین، تفاوت فقط در عنصر دوم الگوهاست. صرف‌نظر از اینکه الگوی ورودی چیست، انتظار می‌رود عنصر اول در خروجی به \(1\) و عنصر سوم به \(-1\) همگرا شود و عنصر دوم به \(1\) یا \(-1\) همگرا شود. انتخاب مقدار عنصر دوم به میزان نزدیکی آن به عنصر دوم بردار ورودی بستگی دارد.
        </p>
        <p>
            اگر الگوی پرتقال بیضوی شکل (غیر ایده‌آل) به شبکه هاپفیلد اعمال شود، خروجی شبکه راپفیلد برای ۳ تکرار اول به صورت زیر همگرا می‌شود:
        </p>
        <div class="math-formula">
            \[
            a(0) = \begin{bmatrix} -1 \\ -1 \\ -1 \end{bmatrix}, \ 
            a(1) = \begin{bmatrix} 0.7 \\ -1 \\ -1 \end{bmatrix}, \ 
            a(2) = \begin{bmatrix} 1 \\ -1 \\ -1 \end{bmatrix}, \ 
            a(3) = \begin{bmatrix} 1 \\ -1 \\ -1 \end{bmatrix}
            \]
        </div>
        <p>
            همانطور که مشاهده می‌شود، شبکه به الگوی پرتقال همگرا شده است. هر سه شبکه بررسی شده در مسئله موردنظر، جواب صحیح را به شکلی متفاوت ارائه می‌کنند.
        </p>

        <h2>مقایسه کلی شبکه‌های پرسپترون، همینگ و هاپفیلد</h2>
        <p>
            سه شبکه‌ای که برای حل مسئله شناسایی الگو مورد بررسی قرار گرفتند – پرسپترون، همینگ، و هاپفیلد – هر کدام رویکرد متفاوتی برای دسته‌بندی الگوها ارائه می‌دهند.
        </p>

        <h3>پرسپترون</h3>
        <ul>
            <li><strong>نوع شبکه:</strong> پیشخوردی تک‌لایه.</li>
            <li><strong>قابلیت:</strong> می‌تواند الگوهایی را که به صورت <strong>خطی قابل تفکیک</strong> هستند، دسته‌بندی کند. خروجی آن یک مقدار منفرد است (مثلاً \(1\) برای یک دسته و \(-1\) برای دسته دیگر).</li>
            <li><strong>محدودیت:</strong> نمی‌تواند الگوهای غیرخطی را تفکیک کند و فقط می‌تواند الگوها را به دو دسته تقسیم کند.</li>
        </ul>

        <h3>شبکه همینگ</h3>
        <ul>
            <li><strong>نوع شبکه:</strong> دارای دو لایه: یک لایه پیشخوردی و یک لایه بازگشتی (رقابتی).</li>
            <li><strong>قابلیت:</strong> وظیفه اصلی آن <strong>پیدا کردن نزدیک‌ترین الگوی مرجع (Prototype)</strong> به بردار ورودی است. از مفهوم <strong>فاصله همینگ</strong> برای بردارهای باینری استفاده می‌کند. خروجی نهایی به صورت "یک از n" است، یعنی تنها یک نرون در لایه بازگشتی خروجی غیر صفر دارد که نشان‌دهنده الگوی نزدیک‌تر است.</li>
            <li><strong>نحوه عملکرد:</strong> لایه پیشخوردی ضرب داخلی ورودی را با هر الگوی مرجع محاسبه می‌کند. لایه بازگشتی نرون‌ها را به رقابت می‌اندازد تا نرون مرتبط با نزدیک‌ترین الگو برنده شود.</li>
        </ul>

        <h3>شبکه هاپفیلد</h3>
        <ul>
            <li><strong>نوع شبکه:</strong> بازگشتی و حافظه انجمنی.</li>
            <li><strong>قابلیت:</strong> به عنوان یک <strong>حافظه انجمنی</strong> عمل می‌کند؛ یعنی با دریافت یک الگوی ورودی (حتی اگر ناقص یا نویزی باشد)، آن را به نزدیک‌ترین الگوی مرجع کامل (که در وزن‌های شبکه ذخیره شده) "یادآوری" می‌کند و در خروجی نمایش می‌دهد.</li>
            <li><strong>نحوه عملکرد:</strong> نرون‌ها با بردار ورودی مقداردهی اولیه می‌شوند و شبکه به صورت تکراری خروجی‌های خود را به‌روزرسانی می‌کند تا زمانی که به یک حالت پایدار همگرا شود. تابع انتقال آن معمولاً از نوع اشباع‌کننده است.</li>
        </ul>

        <h3>جدول مقایسه</h3>
        <table>
            <tr>
                <th>ویژگی</th>
                <th>پرسپترون</th>
                <th>شبکه همینگ</th>
                <th>شبکه هاپفیلد</th>
            </tr>
            <tr>
                <td><strong>نوع شبکه</strong></td>
                <td>پیشخوردی تک‌لایه</td>
                <td>ترکیبی (پیشخوردی + بازگشتی)</td>
                <td>بازگشتی</td>
            </tr>
            <tr>
                <td><strong>وظیفه اصلی</strong></td>
                <td>طبقه‌بندی خطی</td>
                <td>یافتن نزدیک‌ترین الگوی مرجع (فاصله همینگ)</td>
                <td>حافظه انجمنی، بازیابی/بازسازی الگو</td>
            </tr>
            <tr>
                <td><strong>خروجی</strong></td>
                <td>یک مقدار منفرد (مثلاً \(1\) یا \(-1\))</td>
                <td>نرون برنده (نشان‌دهنده شماره الگو)</td>
                <td>الگوی کامل بازسازی شده</td>
            </tr>
            <tr>
                <td><strong>قابلیت تفکیک</strong></td>
                <td>فقط خطی</td>
                <td>بر اساس نزدیکی به الگوهای مرجع</td>
                <td>بازسازی از ورودی‌های ناقص/نویزدار</td>
            </tr>
            <tr>
                <td><strong>پیچیدگی طراحی</strong></td>
                <td>نسبتاً ساده برای خطی</td>
                <td>پیچیده‌تر از پرسپترون (دو لایه)</td>
                <td>نسبتاً پیچیده (همگرایی و طراحی وزن‌ها)</td>
            </tr>
            <tr>
                <td><strong>کاربرد عمده</strong></td>
                <td>مسائل طبقه‌بندی دوتایی خطی</td>
                <td>تشخیص الگو، سیستم‌های تصمیم‌گیری</td>
                <td>حافظه انجمنی، بهینه‌سازی، تصحیح خطا</td>
            </tr>
        </table>

        <p>
            به طور خلاصه، هر سه شبکه می‌توانند الگوها را شناسایی کنند، اما با رویکردها و قابلیت‌های متفاوت: پرسپترون برای جداسازی‌های خطی مناسب است، همینگ برای یافتن نزدیک‌ترین الگو از مجموعه الگوهای مرجع، و هاپفیلد برای بازسازی الگوهای کامل از روی ورودی‌های ناقص یا نویزدار عمل می‌کند. انتخاب هر یک از این شبکه‌ها بستگی به نوع مسئله شناسایی الگو و ماهیت داده‌ها دارد.
        </p>
    </div>
</body>
</html>